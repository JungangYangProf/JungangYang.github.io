<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
	<style>
		body{
			color: #333;
		}
		#container{
			min-width: 1000px;
			width: 1000px;
/*			overflow: auto;
*/			margin: 50px auto;padding: 30px;
			/*zoom: 1;*/
*//*			border: 1px solid #ccc;background: #fc9;color: #fff;
*/		}
		#left{
			float: left;
			width: 230px;
			height: 250px;
			margin-left: 0px;
		}
		#right{
			float: left;
			width: auto;
			margin-left: 30px;
		}
		#name{
			font-size: 22.0pt;
		    mso-bidi-font-size: 24.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		        font-weight: bold;
		}
		#info{
		    font-size: 16.0pt;
		    mso-bidi-font-size: 16.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		    margin-top: 30px;
		    margin-left: 5px;
		    margin-bottom: 10px;
		    
		}
		.clear{clear:both; height: 0; line-height: 0; font-size: 0}
		.Bio{
			font-size:16.0pt;
			mso-bidi-font-size:17.0pt;
			line-height:150%;
			font-family:Times;
			mso-bidi-font-family:Lato-Regular;
			text-align: justify;
		}
		span.SpellE {
		    mso-style-name: "";
		    mso-spl-e: yes;
		}
		span.Title{
			    font-size: 22.0pt;
			    mso-bidi-font-size: 17.0pt;
			    font-family: Times;
			    mso-bidi-font-family: Lato-Regular;
			    font: bold;
			    margin-top: 10px;
			    width: 1000px;
		}
		div.section{
			padding-top: 30px;
		}
		
		div.sub-left{
			float: left;
			width: 250px;
						
		}
		div.sub-left img{
			vertical-align: middle;
			horizontal-align: middle;
			margin-top: 10px;
		}
		
		div.sub-left span{
			height: 100%;
			display: inline-block;
			vertical-align: top;
						
		}
		div.sub-right{
			float: left;
			width: 750px;			
		}
		.paper{
			overflow: auto;
			zoom:1;
			border-top: 2px ;
			padding-bottom: 0px;
			min-height: 160px;

		}
		.paperTitle{
			font-size:14pt;
			mso-bidi-font-size:14pt;
			font-family:Calibri;
			mso-bidi-font-family:Calibri;
			margin-top: 10px;
			margin-bottom: 5px;
			font-weight: bold;
		}
		.paperName{
		    font-size: 12pt;
		    mso-bidi-font-size: 12pt;		    
		    font-family: Calibri;
		    mso-bidi-font-family: Times;
		    line-height:160%;
		    font-style: italic;
		}		
		.paperPub{
		    font-size: 14pt;
		    mso-bidi-font-size: 14pt;		    
		    font-family: Calibri;
		    mso-bidi-font-family: Times;		    
		    font-style: italic;
		    line-height:160%;
		}
		.paperLink{
		    font-size: 13.0pt;
		    mso-bidi-font-size: 13.0pt;		    
		    font-family: Calibri;
		    mso-bidi-font-family: Times;
		    line-height:170%;
		}
		.special{
		    margin-top: 0in;
		    margin-bottom: 0in;
		    margin-left: -.9pt;
		    margin-bottom: .0001pt;
		    text-indent: .9pt;
		    mso-pagination: none;
		    tab-stops: 13.75in;
		    mso-layout-grid-align: none;
		    text-autospace: none;
		}
		.long div.sub-left, .long div.sub-right{
			height: 300px;
			width: 980px;

		}
		.short div.sub-left, .short div.sub-right{
			height:150px;

		}
		div.sub-left,div.sub-right{
			height:200px;

		}
	</style>
</head>
<body>
	<div id="container">
		<div id="left">			
			<img width="200" height="230" src="imgs/photo5.jpg">
		</div>
		<div id="right">
			<div id="name">Jungang Yang (杨俊刚) </div>
			<div id="info">

				Professor<p>
				National University of Defense Technology (NUDT)<p>
				Email: yangjungang@nudt.edu.cn<p>				
			</div>
			         <a href="" target="_blank" rel="nofollow"><span>Research Gate</span></a>  |
			         <a href="https://github.com/JungangYangProf" target="_blank" rel="nofollow"><span>Github</span></a>  |
				 <a href="" target="_blank" rel="nofollow"><span>Google Scholar</span></a>  
			
			</div>

		<div class="clear"></div>
		<div class="section">
			<span class="Title"><b>Brief Bio</b></span><p>			
				<div class="Bio">
					Jungang Yang is a professor at the college of Electronic Science and Technology, National University of Defense Technology (NUDT).
					He received his PhD in Information and Communication Engineering in 2013 from NUDT. 
					From 2010 to 2011, he worked as a visiting PhD in the University of Edinburgh, supervised by Professor John Thompson. 
					The current directions of interest include 
					<b style="mso-bidi-font-weight:normal">light field imaging</b>, <b style="mso-bidi-font-weight:normal">image super-resolution</b> and <b style="mso-bidi-font-weight:normal">target detection</b>.</span></p>
				</div>


	<div class="section">
		<span class="Title"><b>News</b></span><p>
		<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		<div class="paper long"><b>
			<div class="sub-right">
			<div class="paperName"><b>	
			2024.03 | Our paper "Real-World Light Field Image Super-Resolution via Degradation Modulation" is accepted by <span style="color:red">IEEE TNNLS</span>.<br>
			2024.03 |Our paper "MTU-Net: Multilevel TransUNet for Space-Based Infrared Tiny Ship Detection" is selected as <span style="color:red">Highly Cited Papers</span> in the latest issue of ESI Index.<br>
			2024.03 | Receive the honour of <span style="color:red">Distinguished Young Scholar of Hunan Province, China</span>.<br>
			2023.10 | Our paper "Representative Coefficient Total Variation for Efficient Infrared Small Target Detection" and "RepISD-Net Learning Efficient Infrared Small-target Detection Network via Structural Re-parameterization" are accepted by <span style="color:red">IEEE TGRS</span>.<br>
			2023.10 | Receive the honour of <span style="color:red">World Top 2% Scientist</span> from Elsevier-Stanford.<br>
			2023.07 | Our paper "Learning Non-Local Spatial-Angular Correlation for Light Field Image Super-Resolution" is accepted by <span style="color:red">ICCV 2023</span>.<br>
			2023.07 | Our paper "Infrared Small Target Detection via Nonconvex Tensor Tucker Decomposition With Factor Prior" is accepted by <span style="color:red">IEEE TGRS</span>.<br>
			2023.06 | Our paper "Infrared Dim and Small Target Detection via Multiple Subspace Learning and Spatial-Temporal Patch-Tensor Model" is selected as <span style="color:red">1% Highly Cited Papers</span> in the latest issue of ESI Index.<br>
			2023.06 | Our paper "Nonconvex Tensor Low-Rank Approximation for Infrared Small Target Detection" is selected as <span style="color:red">1% Highly Cited Papers</span> in the latest issue of ESI Index.<br>
			2023.02 | Our paper "Disentangling Light Fields for Super-Resolution and Disparity Estimation" is selected as <span style="color:red">1% Highly Cited Papers</span> in the latest issue of ESI Index.<br>
			2023.01 | We are organizing <a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/Stereo-Image-SR/tree/NTIRE2023" target="_blank" rel="nofollow">NTIRE Stereo Image SR Challenge</a> and <a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/LF-Image-SR/tree/NTIRE2023" target="_blank" rel="nofollow">NTIRE LF Image SR Challenge</a> at CVPR 2023.<br>	
			2022.12 | Our paper "MTU-Net: Multilevel TransUNet for Space-Based Infrared Tiny Ship Detection" is accepted by <span style="color:red">IEEE TGRS</span>.<br>
			2022.11 | Our paper "Combining Deep Denoiser and Low-rank Priors for Infrared Small Target Detection" is accepted by <span style="color:red">Pattern Recognition</span>.<br>
			2022.06 | Our Paper "Occlusion-Aware Cost Constructor for Light Field Depth Estimation" is accepted by <span style="color:red">CVPR 2022</span>.<br>
			2022.02 | Our paper "Disentangling Light Fields for Super-Resolution and Disparity Estimation" is accepted by <span style="color:red">IEEE TPAMI</span>.<br>
			2022.01 | We are organizing <a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/Stereo-Image-SR/tree/NTIRE2022" target="_blank" rel="nofollow">NTIRE Stereo Image Super-Resolution Challenge</a> at CVPR 2022.<br> 
			2021.11 | Our Paper "Nonconvex Tensor Low-Rank Approximation for Infrared Small Target Detection" is accepted by <span style="color:red">IEEE TGRS</span>.<br>
			2021.10 | Our paper "Spatial-Angular Attention Network for Light Field Reconstruction" is accepted by <span style="color:red">IEEE TIP</span>. <br>	
			2021.07 | Our paper "Learning a Single Network for Scale-Arbitrary Super-Resolution" is accepted to <span style="color:red">ICCV 2021</span>.<br>
			2021.03 | Our paper "Unsupervised Degradation Representation Learning for Blind Super-Resolution" is accepted to <span style="color:red">CVPR 2021</span>.<br>
			2020.11 | Our paper "Light Field Image Super-Resolution Using Deformable Convolution" is accepted by <span style="color:red">IEEE TIP</span>.<br>
			2020.09 | Our paper "Parallax Attention for Unsupervised Stereo Correspondence Learning" is accepted by <span style="color:red">IEEE TPAMI</span>.<br>
			2020.07 | Our paper "Spatial-Angular Interaction for Light Field Image Super-Resolution" is accepted to <span style="color:red">ECCV 2020</span>.<br>	
			2019.12 | Our paper "DeOccNet: Learning to See Through Foreground Occlusions in Light Fields" is accepted to WACV 2020.<br>
			2019.03 | A large-scale dataset for stereo image super-resolution is available online at <a href="https://yingqianwang.github.io/Flickr1024" target="_blank" rel="nofollow">Flickr1024</a>. <br>
			2019.02 | Our paper "Learning Parallax Attention for Stereo Image Super-Resolution" is accepted to <span style="color:red">CVPR 2019</span>.<br>
			2017.10 | Our paper "An attitude jitter correction method for multispectral parallax imagery based on compressive sensing" is accepted by IEEE TGRS Letters<br>
			2014.09 | Our paper "Compressed sensing radar imaging with compensation of observation position error" is accepted by <span style="color:red">IEEE TGRS</span>.<br>
			2014.07 | Our paper "Sparse MIMO array forward-looking GPR imaging based on compressed sensing in clutter environment" is accepted by <span style="color:red">IEEE TGRS</span>.<br>
			2013.07 | Our paper "Segmented reconstruction for compressed sensing SAR imaging" is accepted by <span style="color:red">IEEE TGRS</span>.<br>
			2013.02 | Our paper "Random-frequency SAR imaging based on compressed sensing" is accepted by <span style="color:red">IEEE TGRS</span>.<br>
			2012.05 | Our paper "Synthetic aperture radar imaging using stepped frequency waveform" is accepted by <span style="color:red">IEEE TGRS</span>.<br>
			2011.12 | Our paper "Low-frequency ultra-wideband synthetic aperture radar ground moving target imaging" is accepted by IET Radar, Sonar & Navigation<br>
			2011.07 | Our paper "New approach for SAR imaging of ground moving targets based on a keystone transform" is accepted by IEEE TGRS Letters<br>
			2011.03 | Our paper "An interpolated phase adjustment by contrast enhancement algorithm for SAR" is accepted by IEEE TGRS Letters<br>

			</b></div>
			</b></div>
		</b></div>
	</div>
	
	
	<div class="clear"></div>
	<div class="section">
	<span class="Title"><b>Publications --- 2024</b></span><p><p>
	<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/LF-DMnet_demo.gif">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Real-World Light Field Image Super-Resolution via Degradation Modulation
					</div>
					<div class="paperName">
						Yingqian Wang, Zhengyu Liang, Longguang Wang, <b>Jungang Yang</b>, Wei An, Yulan Guo
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>TNNLS</b></span>, 2024.<br> 
					</div>
					<div class="paperLink">
						| <a href="https://yingqianwang.github.io/LF-DMnet" target="_blank" rel="nofollow">Project Page</a>
						| <a href="https://arxiv.org/pdf/2206.06214.pdf" target="_blank" rel="nofollow">Paper</a>
						| <a href="https://github.com/YingqianWang/LF-DMnet" target="_blank" rel="nofollow">Code</a>
						
					</div>
				</div>
			</div>			
		
	
	
	<div class="clear"></div>
	<div class="section">
	<span class="Title"><b>Publications --- 2023</b></span><p><p>
	<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/EPIT.jpg">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Learning Non-Local Spatial-Angular Correlation for Light Field Image Super-Resolution
					</div>
					<div class="paperName">
						Zhengyu Liang, Yingqian Wang, Longguang Wang, <b>Jungang Yang</b>, Shilin Zhou, Yulan Guo
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>ICCV</b></span>, 2023.<br> 
					</div>
					<div class="paperLink">
						| <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Learning_Non-Local_Spatial-Angular_Correlation_for_Light_Field_Image_Super-Resolution_ICCV_2023_paper.pdf" target="_blank" rel="nofollow">Paper</a>	
						| <a href="https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liang_Learning_Non-Local_Spatial-Angular_ICCV_2023_supplemental.pdf" target="_blank" rel="nofollow">Supp</a>	
						| <a href="https://zhengyuliang24.github.io/EPIT/" target="_blank" rel="nofollow">Webpage</a>		
						| <a href="https://github.com/ZhengyuLiang24/EPIT" target="_blank" rel="nofollow">Code</a>
					</div>
				</div>
			</div>
		
		

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/NTIRE-LFSR.png">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						NTIRE 2023 Challenge on Light Field Image Super-Resolution: Dataset, Methods and Results
					</div>
					<div class="paperName">
						Yingqian Wang, Longguang Wang, Zhengyu Liang, <b>Jungang Yang</b>, Radu Timofte, Yulan Guo et al.
					</div>
					<div class="paperPub">
						CVPRW, 2023.<br>
					</div>
					<div class="paperLink">
						| <a href="https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/papers/Wang_NTIRE_2023_Challenge_on_Light_Field_Image_Super-Resolution_Dataset_Methods_CVPRW_2023_paper.pdf" target="_blank" rel="nofollow">Paper</a>						
						| <a href="https://wyqdatabase.s3.us-west-1.amazonaws.com/NTIRE_2023.mp4" target="_blank" rel="nofollow">Video</a>
						| <a href="https://codalab.lisn.upsaclay.fr/competitions/9201" target="_blank" rel="nofollow">CodaLab</a>
						| <a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/LF-Image-SR/tree/NTIRE2023" target="_blank" rel="nofollow">Github</a>
						| <a href="https://github.com/ZhengyuLiang24/BasicLFSR" target="_blank" rel="nofollow">BasicLFSR Toolbox</a>
					</div>
				</div>
			</div>

						<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/RepISD-Net.png">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						RepISD-Net: Learning Efficient Infrared Small-target Detection Network via Structural Re-parameterization
					</div>
					<div class="paperName">
						Shuanglin Wu, Chao Xiao, Longguang Wang, Yingqian Wang, Jungang Yang, Wei An
					</div>
					<div class="paperPub">
						IEEE TGRS, 2023.<br>
					</div>
						<div class="paperLink">
						| <a href="https://ieeexplore.ieee.org/document/10275114" target="_blank" rel="nofollow">Paper</a>		
						| <a href="https://github.com/dalinlin-Wu/RepISD-Net" target="_blank" rel="nofollow">Code</a>
		
					</div>
				</div>
			</div>
                                       <div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/RCTVW.png">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Representative Coefficient Total Variation for Efficient Infrared Small Target Detection
					</div>
					<div class="paperName">
						Ting Liu, Jungang Yang, Boyang Li, Yingqian Wang, Wei An
					</div>
					<div class="paperPub">
						IEEE TGRS, 2023.<br>
					</div>
						<div class="paperLink">
						| <a href="https://ieeexplore.ieee.org/abstract/document/10286118" target="_blank" rel="nofollow">Paper</a>		
						| <a href="https://github.com/LiuTing20a/RCTVW" target="_blank" rel="nofollow">Code</a>
							 
		 
					</div>
				</div>
			</div>


		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/NFTDGSTV.png">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Infrared Small Target Detection via Nonconvex Tensor Tucker Decomposition with Factor Prior
					</div>
					<div class="paperName">
						Ting Liu, Jungang Yang, Boyang Li, Yingqian Wang, Wei An
					</div>
					<div class="paperPub">
						IEEE TGRS, 2023.<br>
					</div>
						<div class="paperLink">
						| <a href="https://ieeexplore.ieee.org/document/10190750" target="_blank" rel="nofollow">Paper</a>		
						| <a href="https://github.com/LiuTing20a/NFTDGSTV" target="_blank" rel="nofollow">Code</a>

							
		
					</div>
				</div>
			</div>

		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/DCSR.jpg">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Not All Patches Are Equal: Hierarchical Dataset Condensation for Single Image Super-Resolution
					</div>
					<div class="paperName">
						Qingtang Ding, Zhengyu Liang, Longguang Wang, Yingqian Wang, <b>Jungang Yang</b>				</div>
					<div class="paperPub">
						IEEE SPL, 2023.
					</div>
					<div class="paperLink">
						| <a href="https://ieeexplore.ieee.org/document/10305246" target="_blank" rel="nofollow">Paper</a>						
						
					</div>
				</div>
			</div>
		
	
			
			
	
	<div class="clear"></div>
	<div class="section">
	<span class="Title"><b>Publications --- 2022</b></span><p><p>
	<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/DistgLF.png">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Disentangling Light Fields for Super-Resolution and Disparity Estimation
					</div>
					<div class="paperName">
						Yingqian Wang, Longguang Wang, Gaochang Wu, <b>Jungang Yang</b>, Wei An, Jingyi Yu, Yulan Guo
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>IEEE TPAMI</b></span>, 2022. (ESI Highly Cited Paper)<br>
					</div>
					<div class="paperLink">
						| <a href="https://arxiv.org/pdf/2202.10603.pdf" target="_blank" rel="nofollow">Paper</a>
						| <a href="https://yingqianwang.github.io/DistgLF/" target="_blank" rel="nofollow">Project Page</a>
						| <a href="https://mp.weixin.qq.com/s/T3D0TGZN2fZbsRPV1U147A" target="_blank" rel="nofollow">News</a>
						| <a href="https://github.com/YingqianWang/DistgSSR" target="_blank" rel="nofollow">DistgSSR</a>
						| <a href="https://github.com/YingqianWang/DistgASR" target="_blank" rel="nofollow">DistgASR</a>
						| <a href="https://github.com/YingqianWang/DistgDisp" target="_blank" rel="nofollow">DistgDisp</a>
					</div>
				</div>
			</div>
		
		

		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/OACC-Net.png">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Occlusion-Aware Cost Constructor for Light Field Depth Estimation
					</div>
					<div class="paperName">
						Yingqian Wang, Longguang Wang, Zhengyu Liang, <b>Jungang Yang</b>, Wei An, Yulan Guo
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>CVPR</b></span>, 2022.<br> 
					</div>
					<div class="paperLink">
						| <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Occlusion-Aware_Cost_Constructor_for_Light_Field_Depth_Estimation_CVPR_2022_paper.pdf" target="_blank" rel="nofollow">Paper</a>
						| <a href="https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Occlusion-Aware_Cost_Constructor_CVPR_2022_supplemental.pdf" target="_blank" rel="nofollow">Supp</a>	
						| <a href="https://github.com/YingqianWang/OACC-Net" target="_blank" rel="nofollow">Code</a>						
					</div>
				</div>
			</div>
		
		
		
		
		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/LFT_attmap.png">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Light Field Image Super-Resolution with Transformers
					</div>
					<div class="paperName">
						Zhengyu Liang*, Yingqian Wang*, Longguang Wang, <b>Jungang Yang</b>, Shilin Zhou
					</div>
					<div class="paperPub">
						IEEE SPL, 2022.
					</div>
					<div class="paperLink">
						| <a href="https://arxiv.org/pdf/2108.07597.pdf" target="_blank" rel="nofollow">Paper</a>						
						| <a href="https://github.com/ZhengyuLiang24/LFT" target="_blank" rel="nofollow">Code</a>					
					</div>
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/ASTTV-NTLA.png">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Nonconvex Tensor Low-Rank Approximation for Infrared Small Target Detection
					</div>
					<div class="paperName">
						Ting Liu, Jungang Yang, Boyang Li, Chao Xiao, Yang Sun, Yingqian Wang, Wei An
					</div>
					<div class="paperPub">
						IEEE TGRS, 2021.<br>
					</div>
						<div class="paperLink">
						| <a href="https://ieeexplore.ieee.org/abstract/document/9626011" target="_blank" rel="nofollow">Paper</a>		
						| <a href="https://github.com/LiuTing20a/ASTTV-NTLA" target="_blank" rel="nofollow">Code</a>

							  
		
					</div>
				</div>
			</div>

		
	
	<div class="clear"></div>
	<div class="section">
	<span class="Title"><b>Publications --- 2021</b></span><p><p>
	<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
			
		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/DASR.png">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Unsupervised Degradation Representation Learning for Blind Super-Resolution
					</div>
					<div class="paperName">
						Longguang Wang, Yingqian Wang, Xiaoyu Dong, Qingyu Xu, <b>Jungang Yang</b>, Wei An, Yulan Guo
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>CVPR</b></span>, 2021.<br> 
					</div>
					<div class="paperLink">
						| <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Unsupervised_Degradation_Representation_Learning_for_Blind_Super-Resolution_CVPR_2021_paper.pdf" target="_blank" rel="nofollow">Paper</a>
						| <a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Wang_Unsupervised_Degradation_Representation_CVPR_2021_supplemental.pdf" target="_blank" rel="nofollow">Supp</a>
						| <a href="https://www.techbeat.net/talk-info?id=537" target="_blank" rel="nofollow">Video Presentation</a>						
						| <a href="https://mp.weixin.qq.com/s/jmaMObrWwyg6j659tGe-Kw" target="_blank" rel="nofollow">News</a>
						| <a href="https://github.com/LongguangWang/DASR" target="_blank" rel="nofollow">Code</a>						
					</div>
				</div>
			</div>
		
		
		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/ArbSR.jpg">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Learning a Single Network for Scale-Arbitrary Super-Resolution
					</div>
					<div class="paperName">
						Longguang Wang, Yingqian Wang, Zaiping Lin, <b>Jungang Yang</b>, Wei An, Yulan Guo
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>ICCV</b></span>, 2021.<br> 
					</div>
					<div class="paperLink">
						| <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Learning_a_Single_Network_for_Scale-Arbitrary_Super-Resolution_ICCV_2021_paper.pdf" target="_blank" rel="nofollow">Paper</a>
						| <a href="https://longguangwang.github.io/Project/ArbSR/" target="_blank" rel="nofollow">Project Page</a>
						| <a href="https://replicate.ai/longguangwang/arbsr" target="_blank" rel="nofollow">Online Demo</a>
						| <a href="https://mp.weixin.qq.com/s/rDtxbt3OPN1wrSe406mVRg" target="_blank" rel="nofollow">News</a>
						| <a href="https://github.com/LongguangWang/Scale-Arbitrary-SR" target="_blank" rel="nofollow">Code</a> 												
					</div>
				</div>
			</div>
		
	
	<div class="clear"></div>
	<div class="section">
	<span class="Title"><b>Publications --- 2020</b></span><p><p>
	<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		

                <div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/PASMnet.jpg">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Parallax Attention for Unsupervised Stereo Correspondence Learning
					</div>
					<div class="paperName">
						Longguang Wang, Yulan Guo, Yingqian Wang, Zhengfa Liang, Zaiping Lin, <b>Jungang Yang</b>, Wei An
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>IEEE TPAMI</b></span>, 2020 (ESI Highly Cited Paper)<br>
					</div>
					<div class="paperLink">
						| <a href="https://arxiv.org/pdf/2009.08250.pdf" target="_blank" rel="nofollow">Paper</a>						
						| <a href="https://www.shenlanxueyuan.com/open/course/77" target="_blank" rel="nofollow">Tutorial</a>
						| <a href="https://mp.weixin.qq.com/s/EdEwOEm5ttj3IM-6jI_s4A" target="_blank" rel="nofollow">News</a>						
						| <a href="https://yingqianwang.github.io/Flickr1024" target="_blank" rel="nofollow">Dataset</a>
						| <a href="https://github.com/LongguangWang/PAM" target="_blank" rel="nofollow">Code</a>						
					</div>
				</div>
			</div>	
		
		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/LF-DFnet.jpg">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Light Field Image Super-Resolution Using Deformable Convolution
					</div>
					<div class="paperName">
						Yingqian Wang, <b>Jungang Yang</b>, Longguang Wang, Xinyi Ying, Tianhao Wu, Wei An, Yulan Guo
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>IEEE TIP</b></span>, 2020.<br>
					</div>
					<div class="paperLink">
						| <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286855" target="_blank" rel="nofollow">Paper</a>						
						| <a href="https://github.com/YingqianWang/LF-DFnet" target="_blank" rel="nofollow">Code</a>						
					</div>
				</div>
			</div>
		
		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/SFEAFE.jpg">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Spatial-Angular Interaction for Light Field Image Super-Resolution
					</div>
					<div class="paperName">
						Yingqian Wang, Longguang Wang, <b>Jungang Yang</b>, Wei An, Jingyi Yu, Yulan Guo
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>ECCV</b></span>, 2020.<br>
					</div>
					<div class="paperLink">
						| <a href="https://arxiv.org/pdf/1912.07849.pdf" target="_blank" rel="nofollow">Paper</a>						
						| <a href="https://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&mid=2247520164&idx=1&sn=beb7031162b5c173e66a77b01a828e5b&chksm=96f0fdf0a18774e6a9f85e316efd64d9990dca2213e353c2da373b0a6f4004717e9b092923fb&mpshare=1&srcid=07057miMA6psG3L6UHJZOYb1&sharer_sharetime=1593964266602&sharer_shareid=eadfa6ebb7f5bf94747b471d67269b5e&from=timeline&scene=2&subscene=1&clicktime=1593965476&enterid=1593965476&ascene=14&devicetype=Windows+10+x64&version=62090529&nettype=3gnet&abtest_cookie=AAACAA%3D%3D&lang=zh_CN&exportkey=AbY3Hk%2Bj7%2FZr1bhOoseHkrg%3D&pass_ticket=xxF82PuauoRDV3pp3gMzbUWag4Wn9ibURKETDRhWZzgqvAuhhLZpHUAsxPEkeaTP&wx_header=1&key=d197f1f59dba99c28d4c1b99b04b6bd1077e51e74b63c15b1c47bf892712247f8c43b777c67399686f47ac2805132c5cecb7dd7d8fcd8ede07661f7a2dc7733f6be335fc77d4b5033daad98428a3d3ef&uin=MTM2MDA1MjgzOA%3D%3D" target="_blank" rel="nofollow">News</a>
						| <a href="https://wyqdatabase.s3-us-west-1.amazonaws.com/LF-InterNet.mp4" target="_blank" rel="nofollow">Presentation</a>
						| <a href="https://github.com/YingqianWang/LF-InterNet" target="_blank" rel="nofollow">Code</a>						
					</div>
				</div>
			</div>
		
				
			<div class="paper short">
				<div class="sub-left">
					<span></span>					
					<img border="0" width="200" height="130" src="imgs/DeOccNet.jpg">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						DeOccNet: Learning to See Through Foreground Occlusions in Light Fields
					</div>
					<div class="paperName">
						Yingqian Wang, Tianhao Wu, <b>Jungang Yang</b>, Longguang Wang, Wei An, Yulan Guo
					</div>
					<div class="paperPub">
						WACV, 2020.<br>
					</div>
					<div class="paperLink">
						| <a href="https://arxiv.org/pdf/1912.04459.pdf" target="_blank" rel="nofollow">Paper</a>
						| <a href="https://mp.weixin.qq.com/s/0K_NF84wvPJttEARVUGPWA" target="_blank" rel="nofollow">News</a>	
						| <a href="https://yingqianwang.github.io/DeOccNet/Poster.pdf" target="_blank" rel="nofollow">Poster</a>
						| <a href="https://github.com/YingqianWang/DeOccNet" target="_blank" rel="nofollow">Code&Dataset</a>					
					</div>
				</div>
			</div>	
		
		


	<div class="clear"></div>
	<div class="section">
	<span class="Title"><b>Publications --- 2019</b></span><p><p>
	<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
		
		<div class="paper short">
				<div class="sub-left">
					<span></span>					
					<img border="0" width="200" height="120" src="imgs/PASSRnet.jpg">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Learning Parallax Attention for Stereo Image Super-Resolution
					</div>
					<div class="paperName">
						Longguang Wang, Yingqian Wang, Zhengfa Liang, Zaiping Lin, <b>Jungang Yang</b>, Wei An, Yulan Guo
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>CVPR</b></span>, 2019.<br> 
					</div>
					<div class="paperLink">
						| <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Learning_Parallax_Attention_for_Stereo_Image_Super-Resolution_CVPR_2019_paper.pdf" target="_blank" rel="nofollow">Paper</a>						
						| <a href="https://yingqianwang.github.io/Flickr1024" target="_blank" rel="nofollow">Dataset</a>
						| <a href="https://mp.weixin.qq.com/s/zN11cI3dOOp1PDXaCPcRng" target="_blank" rel="nofollow">News</a>
						| <a href="https://github.com/LongguangWang/PASSRnet" target="_blank" rel="nofollow">Code</a>					
					</div>
				</div>
			</div>
		
		
			<div class="paper short">
				<div class="sub-left">
					<span></span>					
					<img border="0" width="200" height="130" src="imgs/Flickr1024.jpg">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Flickr1024: A Large-Scale Dataset for Stereo Image Super-Resolution
					</div>
					<div class="paperName">
						Yingqian Wang, Longguang Wang, <b>Jungang Yang</b>, Wei An, Yulan Guo
					</div>
					<div class="paperPub">
						ICCV Workshop, 2019.<br>
					</div>
					<div class="paperLink">
						| <a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/LCI/Wang_Flickr1024_A_Large-Scale_Dataset_for_Stereo_Image_Super-Resolution_ICCVW_2019_paper.pdf" target="_blank" rel="nofollow">Paper</a>
						| <a href="https://yingqianwang.github.io/Flickr1024" target="_blank" rel="nofollow">Dataset</a>
					</div>
				</div>
			</div>		
		
			
		
<div class="section">
				<span class="Title"><b>Academic Services</b></span><p>
				<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
				<div class="paperName"><b>
					Reviewer:<br>
					<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36" target="_blank" rel="nofollow">IEEE Transactions on Geoscience and Remote Sensing</a> <br>				
					<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83" target="_blank" rel="nofollow">IEEE Transactions on Image Processing</a> <br>
					<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046" target="_blank" rel="nofollow">IEEE Transactions on Multimedia</a> <br>
					<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76" target="_blank" rel="nofollow">IEEE Transactions on Circuits and Systems for Video Technology</a> <br>
					<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6745852" target="_blank" rel="nofollow">IEEE Transactions on Computational Imaging</a> <br>
					<a href="https://www.journals.elsevier.com/pattern-recognition-letters" target="_blank" rel="nofollow">Pattern Recognition Letters</a> <br>			
					......<br>
					<br>
					</b></div>
			</div>		
		

			<div class="section">
				<span class="Title"><b>Awards & Honors</b></span><p>
				<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
				<div class="paperName"><b>
					2024 | Distinguished Young Scholar of Hunan Province, China<br>
					2023 | World Top 2% Scientists of Elsevier-Stanford<br>
					2020 | Young Talents of Hunan Province, China<br>
					2020 | Young Innovative Talents in Science and Technology of Hunan Province, China<br>
					2020 | Second-class prize of National Science of Chinese Institute of Electronics<br>
					2017 | Outstanding Doctoral Dissertation Award of China Education Society of Electronics<br>
					2016 | Outstanding Doctoral Dissertation Award of Hunan Province, China<br>
					2016 | Young Talents of National University of Defense Technology<br>
					2016 | Youth Innovation Award of National University of Defense Technology<br>
					2012 | Doctoral Academic Novice Award, Ministry of Education<br>

				</b></div>
			</div>		
		
			<!-- site visitors begjin -->
			<div style="margin:50px 0;">
				<a href="https://info.flagcounter.com/l4Uj"><img src="https://s11.flagcounter.com/map/l4Uj/size_m/txt_000000/border_CCCCCC/pageviews_1/viewers_0/flags_0/" alt="Flag Counter" border="0"></a>
			</div>
			<!-- site visitors end -->
		
			<!-- Last update time begjin -->
			<div style="border-top: 3px solid #555; text-align: center;">
				<p style="color: #555;">Last updated: 2024-03-26</p>
			</div>
			<!-- Last update time end -->

	</div>
	
</body>
</html>
